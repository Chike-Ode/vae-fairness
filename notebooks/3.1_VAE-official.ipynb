{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487d176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import os\n",
    "# from pl_bolts.models.autoencoders import VAE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c25e359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dfa1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "root_dir = \"/workspace/vae-fairness/\"\n",
    "data_dir = os.path.join(root_dir,\"data\")\n",
    "raw_data_dir = os.path.join(data_dir,\"raw\")\n",
    "raw_german_all = os.path.join(raw_data_dir,\"german.data\")\n",
    "raw_bar_pass = os.path.join(raw_data_dir,\"bar_pass_prediction.csv\")\n",
    "# raw_german_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f85c213a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decile1b</th>\n",
       "      <th>decile3</th>\n",
       "      <th>decile1</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lsat</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>zfygpa</th>\n",
       "      <th>DOB_yr</th>\n",
       "      <th>grad</th>\n",
       "      <th>zgpa</th>\n",
       "      <th>bar1</th>\n",
       "      <th>bar1_yr</th>\n",
       "      <th>bar2</th>\n",
       "      <th>bar2_yr</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>fam_inc</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>parttime</th>\n",
       "      <th>male</th>\n",
       "      <th>race1</th>\n",
       "      <th>race2</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>other</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>pass_bar</th>\n",
       "      <th>bar</th>\n",
       "      <th>bar_passed</th>\n",
       "      <th>tier</th>\n",
       "      <th>index6040</th>\n",
       "      <th>indxgrp</th>\n",
       "      <th>indxgrp2</th>\n",
       "      <th>dnn_bar_pass_prediction</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.33</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>886.842082</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>i 820+</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>649.999987</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>760.526298</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>h 760-820</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>807.894717</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>h 760-820</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.76</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>949.999974</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>i 820+</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>black</td>\n",
       "      <td>a black</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c Failed</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>440.526304</td>\n",
       "      <td>b 400-460</td>\n",
       "      <td>b 400-460</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19642</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>F</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>black</td>\n",
       "      <td>a black</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c Failed</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>333.157888</td>\n",
       "      <td>a under 400</td>\n",
       "      <td>a under 400</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24704</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.80</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>black</td>\n",
       "      <td>a black</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>590.526298</td>\n",
       "      <td>e 580-640</td>\n",
       "      <td>e 580-640</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.88</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.42</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>686.842082</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>0.759128</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.10</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.81</td>\n",
       "      <td>P</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>467.894723</td>\n",
       "      <td>c 460-520</td>\n",
       "      <td>c 460-520</td>\n",
       "      <td>0.330740</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22407 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       decile1b  decile3  decile1  sex  race  cluster  lsat  ugpa  zfygpa  \\\n",
       "ID                                                                          \n",
       "2          10.0     10.0     10.0  1.0   7.0      1.0  44.0   3.5    1.33   \n",
       "3           5.0      4.0      5.0  1.0   7.0      2.0  29.0   3.5   -0.11   \n",
       "36          3.0      2.0      3.0  2.0   7.0      3.0  36.0   3.5   -0.64   \n",
       "52          7.0      4.0      7.0  2.0   7.0      3.0  39.0   3.5    0.34   \n",
       "55          9.0      8.0      9.0  2.0   7.0      4.0  48.0   3.5    1.02   \n",
       "...         ...      ...      ...  ...   ...      ...   ...   ...     ...   \n",
       "10695       3.0      1.0      3.0  2.0   3.0      6.0  26.5   1.8   -0.58   \n",
       "19642       2.0      1.0      3.0  2.0   3.0      6.0  19.7   1.8   -0.64   \n",
       "24704       7.0      8.0      7.0  2.0   3.0      3.0  36.0   1.8    0.41   \n",
       "10000      10.0     10.0     10.0  2.0   7.0      3.0  44.0   1.5    1.88   \n",
       "10684       9.0      8.0      9.0  2.0   7.0      6.0  29.5   1.6    1.10   \n",
       "\n",
       "       DOB_yr grad  zgpa bar1  bar1_yr bar2  bar2_yr  fulltime  fam_inc   age  \\\n",
       "ID                                                                              \n",
       "2        69.0    Y  1.88    P      7.0    P     94.0       1.0      5.0 -62.0   \n",
       "3        69.0    Y -0.57    P      7.0    P     94.0       1.0      4.0 -62.0   \n",
       "36       65.0    Y -1.12    P      7.0    P     94.0       1.0      1.0 -58.0   \n",
       "52       58.0    Y -0.49    P      7.0    P     94.0       1.0      4.0 -51.0   \n",
       "55       68.0    Y  0.76    P      7.0    P     94.0       1.0      4.0 -61.0   \n",
       "...       ...  ...   ...  ...      ...  ...      ...       ...      ...   ...   \n",
       "10695    64.0    Y -1.49    F      2.0    F     95.0       1.0      2.0 -62.0   \n",
       "19642    64.0    Y -1.36    F      7.0    F     94.0       1.0      3.0 -57.0   \n",
       "24704    66.0    Y  0.80    P      7.0    P     95.0       2.0      3.0 -59.0   \n",
       "10000    58.0    Y  1.42    P      7.0    P     95.0       2.0      3.0 -51.0   \n",
       "10684    59.0    Y  0.81    P      2.0    P     94.0       1.0      3.0 -57.0   \n",
       "\n",
       "       gender  parttime  male  race1    race2 Dropout  other  asian  black  \\\n",
       "ID                                                                           \n",
       "2      female       0.0   0.0  white  b white      NO      0      0      0   \n",
       "3      female       0.0   0.0  white  b white      NO      0      0      0   \n",
       "36       male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "52       male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "55       male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "...       ...       ...   ...    ...      ...     ...    ...    ...    ...   \n",
       "10695    male       0.0   1.0  black  a black      NO      0      0      1   \n",
       "19642    male       0.0   1.0  black  a black      NO      0      0      1   \n",
       "24704    male       1.0   1.0  black  a black      NO      0      0      1   \n",
       "10000    male       1.0   1.0  white  b white      NO      0      0      0   \n",
       "10684    male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "\n",
       "       hisp  pass_bar                bar  bar_passed  tier   index6040  \\\n",
       "ID                                                                       \n",
       "2         0         1  a Passed 1st time        True   4.0  886.842082   \n",
       "3         0         1  a Passed 1st time        True   2.0  649.999987   \n",
       "36        0         1  a Passed 1st time        True   3.0  760.526298   \n",
       "52        0         1  a Passed 1st time        True   3.0  807.894717   \n",
       "55        0         1  a Passed 1st time        True   5.0  949.999974   \n",
       "...     ...       ...                ...         ...   ...         ...   \n",
       "10695     0         0           c Failed       False   1.0  440.526304   \n",
       "19642     0         0           c Failed       False   1.0  333.157888   \n",
       "24704     0         1  a Passed 1st time        True   3.0  590.526298   \n",
       "10000     0         1  a Passed 1st time        True   3.0  686.842082   \n",
       "10684     0         1  a Passed 1st time        True   1.0  467.894723   \n",
       "\n",
       "           indxgrp     indxgrp2  dnn_bar_pass_prediction  gpa  \n",
       "ID                                                             \n",
       "2           g 700+       i 820+                 0.979804  3.5  \n",
       "3        f 640-700    f 640-700                 0.979804  3.5  \n",
       "36          g 700+    h 760-820                 0.979804  3.5  \n",
       "52          g 700+    h 760-820                 0.979804  3.5  \n",
       "55          g 700+       i 820+                 0.979804  3.5  \n",
       "...            ...          ...                      ...  ...  \n",
       "10695    b 400-460    b 400-460                 0.557568  1.8  \n",
       "19642  a under 400  a under 400                 0.557568  1.8  \n",
       "24704    e 580-640    e 580-640                 0.557568  1.8  \n",
       "10000    f 640-700    f 640-700                 0.759128  1.5  \n",
       "10684    c 460-520    c 460-520                 0.330740  1.6  \n",
       "\n",
       "[22407 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_df = pd.read_csv(raw_bar_pass).set_index('ID')\n",
    "bar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445db6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bar_df['age'] = bar_df['age'].abs()\n",
    "\n",
    "drop_cols_dup = ['DOB_yr','sex','bar2','race2','other','asian','black','hisp','bar','bar_passed','indxgrp','ugpa','indxgrp2','gender','race1'] #,'bar2_yr'\n",
    "drop_cols_na = ['decile1b','decile3','decile1','zgpa','zfygpa']\n",
    "one_hot_cols = ['grad','bar1','race','Dropout']\n",
    "bar_df = bar_df.drop(columns = drop_cols_dup + drop_cols_na)\n",
    "bar_df = bar_df.dropna()\n",
    "bar_df = pd.get_dummies(bar_df,columns = one_hot_cols)\n",
    "# sens_attri = ['other','asian','black','hisp', 'male','race1','race2', 'sex','race','DOB_yr','age','gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d236851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21894, 29)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7046faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(bar_df, test_size=0.2, random_state=42)\n",
    "scaler = MinMaxScaler()#StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a6d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(X_train_scaled.values,dtype=torch.float32)#.shape\n",
    "X_train_torch = torch.tensor(X_train_scaled,dtype=torch.float32)#.shape\n",
    "X_test_torch = torch.tensor(X_test_scaled,dtype=torch.float32)#.shape\n",
    "# trainloader=DataLoader(dataset=X_train_torch,batch_size=1024)\n",
    "# testloader=DataLoader(dataset=X_test_torch,batch_size=1024)\n",
    "\n",
    "trainloader = DataLoader(dataset=X_train_torch,batch_size=1024)\n",
    "testloader = DataLoader(dataset=X_test_torch,batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "967c19c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17515, 29])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6fc3fbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=29, out_features=15, bias=True)\n",
      "      (1): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=15, out_features=7, bias=True)\n",
      "      (4): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=7, out_features=7, bias=True)\n",
      "      (7): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=7, out_features=7, bias=True)\n",
      "      (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=7, out_features=15, bias=True)\n",
      "      (4): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=15, out_features=29, bias=True)\n",
      "      (7): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "0 0.5518671274185181\n",
      "1 0.4115910828113556\n",
      "2 0.30587175488471985\n",
      "3 0.24698279798030853\n",
      "4 0.21353569626808167\n",
      "5 0.18911190330982208\n",
      "6 0.1718212068080902\n",
      "7 0.1578061282634735\n",
      "8 0.14843322336673737\n",
      "9 0.1417233794927597\n",
      "10 0.13682225346565247\n",
      "11 0.13320425152778625\n",
      "12 0.1301145851612091\n",
      "13 0.12726975977420807\n",
      "14 0.12469659745693207\n",
      "15 0.12262523919343948\n",
      "16 0.1206614300608635\n",
      "17 0.11896844208240509\n",
      "18 0.11732269078493118\n",
      "19 0.11574079096317291\n",
      "20 0.1140761524438858\n",
      "21 0.1126546859741211\n",
      "22 0.11122559010982513\n",
      "23 0.11006524413824081\n",
      "24 0.10899775475263596\n",
      "25 0.10770577192306519\n",
      "26 0.10646724700927734\n",
      "27 0.10556099563837051\n",
      "28 0.10428109765052795\n",
      "29 0.10278292000293732\n",
      "30 0.10114879161119461\n",
      "31 0.09934946894645691\n",
      "32 0.09535359591245651\n",
      "33 0.0934869796037674\n",
      "34 0.09244503080844879\n",
      "35 0.09178119152784348\n",
      "36 0.09125678241252899\n",
      "37 0.09076598286628723\n",
      "38 0.09047733247280121\n",
      "39 0.09011896699666977\n",
      "40 0.08878061175346375\n",
      "41 0.0883588194847107\n",
      "42 0.0879690870642662\n",
      "43 0.0876474678516388\n",
      "44 0.08747895061969757\n",
      "45 0.08732027560472488\n",
      "46 0.08698084950447083\n",
      "47 0.0864960178732872\n",
      "48 0.08607754111289978\n",
      "49 0.08485518395900726\n",
      "50 0.08436193317174911\n",
      "51 0.08406252413988113\n",
      "52 0.08337664604187012\n",
      "53 0.08236804604530334\n",
      "54 0.08074185252189636\n",
      "55 0.07936324179172516\n",
      "56 0.07854209840297699\n",
      "57 0.07802648097276688\n",
      "58 0.07766564935445786\n",
      "59 0.07739898562431335\n",
      "60 0.07719045132398605\n",
      "61 0.07701022177934647\n",
      "62 0.07688628137111664\n",
      "63 0.07671650499105453\n",
      "64 0.0765322670340538\n",
      "65 0.07601295411586761\n",
      "66 0.07580091059207916\n",
      "67 0.07565049827098846\n",
      "68 0.07538359612226486\n",
      "69 0.0750809833407402\n",
      "70 0.07495949417352676\n",
      "71 0.07484354078769684\n",
      "72 0.07477179169654846\n",
      "73 0.07467541098594666\n",
      "74 0.0746346265077591\n",
      "75 0.07445083558559418\n",
      "76 0.0744108110666275\n",
      "77 0.07428574562072754\n",
      "78 0.07414254546165466\n",
      "79 0.07404354214668274\n",
      "80 0.0739031508564949\n",
      "81 0.07376011461019516\n",
      "82 0.07361049950122833\n",
      "83 0.07341726869344711\n",
      "84 0.0731179267168045\n",
      "85 0.07282716780900955\n",
      "86 0.07269403338432312\n",
      "87 0.07235508412122726\n",
      "88 0.06720275431871414\n",
      "89 0.055765338242053986\n",
      "90 0.053096529096364975\n",
      "91 0.051907073706388474\n",
      "92 0.051363505423069\n",
      "93 0.05096645653247833\n",
      "94 0.05069613456726074\n",
      "95 0.05052577704191208\n",
      "96 0.0503612719476223\n",
      "97 0.0502794086933136\n",
      "98 0.05012325569987297\n",
      "99 0.04969257488846779\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,n_feats,layer_shape = {1:15,2:7,3:7}):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(self._generate_layers(n_feats = n_feats,layer_shape = layer_shape,block = 'encoder'))\n",
    "        self.decoder = torch.nn.Sequential(self._generate_layers(n_feats = n_feats,layer_shape = layer_shape,block = 'decoder'))\n",
    "        \n",
    "    def _generate_layers(self,n_feats,layer_shape,block):\n",
    "        input_layer_shape = {0:n_feats}\n",
    "        input_layer_shape.update(layer_shape)\n",
    "        layer_shape = input_layer_shape\n",
    "        if block == 'decoder':\n",
    "            layer_shape = dict(reversed(list(layer_shape.items())))\n",
    "        layers = []\n",
    "#         first_layer = next(iter(layer_shape))\n",
    "#         layers.append(nn.Linear(layer_shape[first_layer],layer_shape[first_layer + 1]))\n",
    "#         layers.append(nn.BatchNorm1d(num_features = layer_shape[first_layer+1]))\n",
    "#         layers.append(nn.ReLU())\n",
    "        for index,layer in enumerate(layer_shape):\n",
    "            if index == len(layer_shape) - 1:\n",
    "                # skipping last layer \n",
    "                break\n",
    "            if block == 'decoder':\n",
    "                next_layer = layer - 1\n",
    "            elif block == 'encoder':\n",
    "                next_layer = layer + 1\n",
    "            layers.append(nn.Linear(layer_shape[layer],layer_shape[next_layer]))\n",
    "            layers.append(nn.BatchNorm1d(num_features = layer_shape[next_layer]))\n",
    "            layers.append(nn.ReLU())\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "n_feats = X_train_torch.shape[1]\n",
    "\n",
    "model = Autoencoder(n_feats).to(device)\n",
    "\n",
    "# summary(model, (15, 29))\n",
    "print(model)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    " \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-3,\n",
    "                             weight_decay = 1e-8)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for idx, x in enumerate(trainloader):\n",
    "#         x = x.squeeze()\n",
    "#         x = x / x.max()\n",
    "        x_pred = model(x) # forward pass\n",
    "        loss = loss_fn(x_pred, x)\n",
    "        if idx % 1024 == 0:\n",
    "            print(epoch, loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()         # backward pass\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6118a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    # https://arxiv.org/abs/1312.6114 (Appendix B)\n",
    "    cross_entropy = F.binary_cross_entropy(recon_x, x, size_average=False)        \n",
    "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return cross_entropy + kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8811b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=29, out_features=15, bias=True)\n",
      "      (1): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=15, out_features=7, bias=True)\n",
      "      (4): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=7, out_features=7, bias=True)\n",
      "      (7): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=7, out_features=7, bias=True)\n",
      "      (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=7, out_features=15, bias=True)\n",
      "      (4): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=15, out_features=29, bias=True)\n",
      "      (7): BatchNorm1d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mu_layer): Linear(in_features=7, out_features=7, bias=True)\n",
      "  (logvar_layer): Linear(in_features=7, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 77\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainloader):\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#         x = x.squeeze()\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m#         x = x / x.max()\u001b[39;00m\n\u001b[1;32m     76\u001b[0m         recon_x, mu, logvar \u001b[38;5;241m=\u001b[39m model(x) \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#         loss = loss_fn(x_pred, x)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(recon_x, x, mu, logvar)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(recon_x, x, mu, logvar):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# https://arxiv.org/abs/1312.6114 (Appendix B)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     cross_entropy \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m        \n\u001b[1;32m      4\u001b[0m     kl \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m logvar \u001b[38;5;241m-\u001b[39m mu\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m logvar\u001b[38;5;241m.\u001b[39mexp())\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_entropy \u001b[38;5;241m+\u001b[39m kl\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:3095\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3092\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3093\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,n_feats,layer_shape = {1:15,2:7,3:7}):\n",
    "        super(VAE,self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(self._generate_layers(n_feats = n_feats,layer_shape = layer_shape,block = 'encoder'))\n",
    "        self.decoder = torch.nn.Sequential(self._generate_layers(n_feats = n_feats,layer_shape = layer_shape,block = 'decoder'))\n",
    "        latent_dim = layer_shape[max(layer_shape, key=int)]\n",
    "        self.mu_layer = nn.Linear(latent_dim, latent_dim)  # mu layer\n",
    "        self.logvar_layer = nn.Linear(latent_dim, latent_dim)  # logvariance layer\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _generate_layers(self,n_feats,layer_shape,block):\n",
    "        input_layer_shape = {0:n_feats}\n",
    "        input_layer_shape.update(layer_shape)\n",
    "        layer_shape = input_layer_shape\n",
    "        if block == 'decoder':\n",
    "            layer_shape = dict(reversed(list(layer_shape.items())))\n",
    "        layers = []\n",
    "#         first_layer = next(iter(layer_shape))\n",
    "#         layers.append(nn.Linear(layer_shape[first_layer],layer_shape[first_layer + 1]))\n",
    "#         layers.append(nn.BatchNorm1d(num_features = layer_shape[first_layer+1]))\n",
    "#         layers.append(nn.ReLU())\n",
    "        for index,layer in enumerate(layer_shape):\n",
    "            if index == len(layer_shape) - 1:\n",
    "                # skipping last layer \n",
    "                break\n",
    "            if block == 'decoder':\n",
    "                next_layer = layer - 1\n",
    "            elif block == 'encoder':\n",
    "                next_layer = layer + 1\n",
    "            layers.append(nn.Linear(layer_shape[layer],layer_shape[next_layer]))\n",
    "            layers.append(nn.BatchNorm1d(num_features = layer_shape[next_layer]))\n",
    "            layers.append(nn.ReLU())\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling\n",
    "        return sample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = self.encoder(x)\n",
    "        # get `mu` and `log_var`\n",
    "        mu = self.mu_layer(hidden)\n",
    "        logvar = self.logvar_layer(hidden)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "#         z = self.fc2(z)\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, logvar\n",
    "    \n",
    "    \n",
    "    \n",
    "n_feats = X_train_torch.shape[1]\n",
    "\n",
    "model = VAE(n_feats).to(device)\n",
    "\n",
    "# summary(model, (15, 29))\n",
    "print(model)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    " \n",
    "# Using an Adam Optimizer with lr = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr = 1e-3,\n",
    "                             weight_decay = 1e-8)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for idx, x in enumerate(trainloader):\n",
    "#         x = x.squeeze()\n",
    "#         x = x / x.max()\n",
    "        recon_x, mu, logvar = model(x) # forward pass\n",
    "        loss = loss_function(recon_x, x, mu, logvar)\n",
    "#         loss = loss_fn(x_pred, x)\n",
    "        if idx % 1024 == 0:\n",
    "            print(epoch, loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()         # backward pass\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(n_feats,layer_shape = {1:15,2:7,3:7}):\n",
    "        super(self,Autoencoder).__init__()\n",
    "        self.encoder = torch.nn.Sequential(self._generate_layers(n_feats,layer_shape,block = 'encoder'))\n",
    "        self.decoder = torch.nn.Sequential(self._generate_layers(n_feats,layer_shape,block = 'decoder'))\n",
    "        \n",
    "    def _generate_layers(n_feats,layer_shape,block):\n",
    "        input_layer_shape = {0:n_feats}\n",
    "        input_layer_shape.update(layer_shape)\n",
    "        layer_shape = input_layer_shape\n",
    "        if block == 'decoder':\n",
    "            layer_shape = dict(reversed(list(layer_shape.items())))\n",
    "        layers = []\n",
    "#         first_layer = next(iter(layer_shape))\n",
    "#         layers.append(nn.Linear(layer_shape[first_layer],layer_shape[first_layer + 1]))\n",
    "#         layers.append(nn.BatchNorm1d(num_features = layer_shape[first_layer+1]))\n",
    "#         layers.append(nn.ReLU())\n",
    "        for index,layer in enumerate(layer_shape):\n",
    "            if index == len(layer_shape) - 1:\n",
    "                break\n",
    "            if block == 'decoder':\n",
    "                next_layer = layer - 1\n",
    "            elif block == 'encoder':\n",
    "                next_layer = layer + 1\n",
    "            layers.append(nn.Linear(layer_shape[layer],layer_shape[next_layer]))\n",
    "            layers.append(nn.BatchNorm1d(num_features = layer_shape[next_layer]))\n",
    "            layers.append(nn.ReLU())\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "n_feats = X_train_torch.shape[1]\n",
    "\n",
    "model = AutoEncoder(n_feats).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_mse = nn.MSELoss()\n",
    "\n",
    "\n",
    "epochs = 1500\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        print(data)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    if epoch % 200 == 0:        \n",
    "        print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))\n",
    "        \n",
    "def test(epoch):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            if epoch % 200 == 0:        \n",
    "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "                    epoch, test_loss / len(testloader.dataset)))\n",
    "            test_losses.append(test_loss / len(testloader.dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
