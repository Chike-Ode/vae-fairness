{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c216d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d5a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import os\n",
    "# from pl_bolts.models.autoencoders import VAE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af72f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda60a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "root_dir = \"/workspace/vae-fairness/\"\n",
    "data_dir = os.path.join(root_dir,\"data\")\n",
    "raw_data_dir = os.path.join(data_dir,\"raw\")\n",
    "raw_german_all = os.path.join(raw_data_dir,\"german.data\")\n",
    "raw_bar_pass = os.path.join(raw_data_dir,\"bar_pass_prediction.csv\")\n",
    "# raw_german_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb2dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decile1b</th>\n",
       "      <th>decile3</th>\n",
       "      <th>decile1</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>cluster</th>\n",
       "      <th>lsat</th>\n",
       "      <th>ugpa</th>\n",
       "      <th>zfygpa</th>\n",
       "      <th>DOB_yr</th>\n",
       "      <th>grad</th>\n",
       "      <th>zgpa</th>\n",
       "      <th>bar1</th>\n",
       "      <th>bar1_yr</th>\n",
       "      <th>bar2</th>\n",
       "      <th>bar2_yr</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>fam_inc</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>parttime</th>\n",
       "      <th>male</th>\n",
       "      <th>race1</th>\n",
       "      <th>race2</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>other</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>pass_bar</th>\n",
       "      <th>bar</th>\n",
       "      <th>bar_passed</th>\n",
       "      <th>tier</th>\n",
       "      <th>index6040</th>\n",
       "      <th>indxgrp</th>\n",
       "      <th>indxgrp2</th>\n",
       "      <th>dnn_bar_pass_prediction</th>\n",
       "      <th>gpa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.33</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.88</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>886.842082</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>i 820+</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>649.999987</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>760.526298</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>h 760-820</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.34</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>807.894717</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>h 760-820</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.02</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.76</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>949.999974</td>\n",
       "      <td>g 700+</td>\n",
       "      <td>i 820+</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10695</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>F</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-62.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>black</td>\n",
       "      <td>a black</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c Failed</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>440.526304</td>\n",
       "      <td>b 400-460</td>\n",
       "      <td>b 400-460</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19642</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>F</td>\n",
       "      <td>7.0</td>\n",
       "      <td>F</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>black</td>\n",
       "      <td>a black</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c Failed</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>333.157888</td>\n",
       "      <td>a under 400</td>\n",
       "      <td>a under 400</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24704</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.80</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>black</td>\n",
       "      <td>a black</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>590.526298</td>\n",
       "      <td>e 580-640</td>\n",
       "      <td>e 580-640</td>\n",
       "      <td>0.557568</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.88</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.42</td>\n",
       "      <td>P</td>\n",
       "      <td>7.0</td>\n",
       "      <td>P</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>686.842082</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>f 640-700</td>\n",
       "      <td>0.759128</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.10</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.81</td>\n",
       "      <td>P</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>white</td>\n",
       "      <td>b white</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a Passed 1st time</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>467.894723</td>\n",
       "      <td>c 460-520</td>\n",
       "      <td>c 460-520</td>\n",
       "      <td>0.330740</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22407 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       decile1b  decile3  decile1  sex  race  cluster  lsat  ugpa  zfygpa  \\\n",
       "ID                                                                          \n",
       "2          10.0     10.0     10.0  1.0   7.0      1.0  44.0   3.5    1.33   \n",
       "3           5.0      4.0      5.0  1.0   7.0      2.0  29.0   3.5   -0.11   \n",
       "36          3.0      2.0      3.0  2.0   7.0      3.0  36.0   3.5   -0.64   \n",
       "52          7.0      4.0      7.0  2.0   7.0      3.0  39.0   3.5    0.34   \n",
       "55          9.0      8.0      9.0  2.0   7.0      4.0  48.0   3.5    1.02   \n",
       "...         ...      ...      ...  ...   ...      ...   ...   ...     ...   \n",
       "10695       3.0      1.0      3.0  2.0   3.0      6.0  26.5   1.8   -0.58   \n",
       "19642       2.0      1.0      3.0  2.0   3.0      6.0  19.7   1.8   -0.64   \n",
       "24704       7.0      8.0      7.0  2.0   3.0      3.0  36.0   1.8    0.41   \n",
       "10000      10.0     10.0     10.0  2.0   7.0      3.0  44.0   1.5    1.88   \n",
       "10684       9.0      8.0      9.0  2.0   7.0      6.0  29.5   1.6    1.10   \n",
       "\n",
       "       DOB_yr grad  zgpa bar1  bar1_yr bar2  bar2_yr  fulltime  fam_inc   age  \\\n",
       "ID                                                                              \n",
       "2        69.0    Y  1.88    P      7.0    P     94.0       1.0      5.0 -62.0   \n",
       "3        69.0    Y -0.57    P      7.0    P     94.0       1.0      4.0 -62.0   \n",
       "36       65.0    Y -1.12    P      7.0    P     94.0       1.0      1.0 -58.0   \n",
       "52       58.0    Y -0.49    P      7.0    P     94.0       1.0      4.0 -51.0   \n",
       "55       68.0    Y  0.76    P      7.0    P     94.0       1.0      4.0 -61.0   \n",
       "...       ...  ...   ...  ...      ...  ...      ...       ...      ...   ...   \n",
       "10695    64.0    Y -1.49    F      2.0    F     95.0       1.0      2.0 -62.0   \n",
       "19642    64.0    Y -1.36    F      7.0    F     94.0       1.0      3.0 -57.0   \n",
       "24704    66.0    Y  0.80    P      7.0    P     95.0       2.0      3.0 -59.0   \n",
       "10000    58.0    Y  1.42    P      7.0    P     95.0       2.0      3.0 -51.0   \n",
       "10684    59.0    Y  0.81    P      2.0    P     94.0       1.0      3.0 -57.0   \n",
       "\n",
       "       gender  parttime  male  race1    race2 Dropout  other  asian  black  \\\n",
       "ID                                                                           \n",
       "2      female       0.0   0.0  white  b white      NO      0      0      0   \n",
       "3      female       0.0   0.0  white  b white      NO      0      0      0   \n",
       "36       male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "52       male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "55       male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "...       ...       ...   ...    ...      ...     ...    ...    ...    ...   \n",
       "10695    male       0.0   1.0  black  a black      NO      0      0      1   \n",
       "19642    male       0.0   1.0  black  a black      NO      0      0      1   \n",
       "24704    male       1.0   1.0  black  a black      NO      0      0      1   \n",
       "10000    male       1.0   1.0  white  b white      NO      0      0      0   \n",
       "10684    male       0.0   1.0  white  b white      NO      0      0      0   \n",
       "\n",
       "       hisp  pass_bar                bar  bar_passed  tier   index6040  \\\n",
       "ID                                                                       \n",
       "2         0         1  a Passed 1st time        True   4.0  886.842082   \n",
       "3         0         1  a Passed 1st time        True   2.0  649.999987   \n",
       "36        0         1  a Passed 1st time        True   3.0  760.526298   \n",
       "52        0         1  a Passed 1st time        True   3.0  807.894717   \n",
       "55        0         1  a Passed 1st time        True   5.0  949.999974   \n",
       "...     ...       ...                ...         ...   ...         ...   \n",
       "10695     0         0           c Failed       False   1.0  440.526304   \n",
       "19642     0         0           c Failed       False   1.0  333.157888   \n",
       "24704     0         1  a Passed 1st time        True   3.0  590.526298   \n",
       "10000     0         1  a Passed 1st time        True   3.0  686.842082   \n",
       "10684     0         1  a Passed 1st time        True   1.0  467.894723   \n",
       "\n",
       "           indxgrp     indxgrp2  dnn_bar_pass_prediction  gpa  \n",
       "ID                                                             \n",
       "2           g 700+       i 820+                 0.979804  3.5  \n",
       "3        f 640-700    f 640-700                 0.979804  3.5  \n",
       "36          g 700+    h 760-820                 0.979804  3.5  \n",
       "52          g 700+    h 760-820                 0.979804  3.5  \n",
       "55          g 700+       i 820+                 0.979804  3.5  \n",
       "...            ...          ...                      ...  ...  \n",
       "10695    b 400-460    b 400-460                 0.557568  1.8  \n",
       "19642  a under 400  a under 400                 0.557568  1.8  \n",
       "24704    e 580-640    e 580-640                 0.557568  1.8  \n",
       "10000    f 640-700    f 640-700                 0.759128  1.5  \n",
       "10684    c 460-520    c 460-520                 0.330740  1.6  \n",
       "\n",
       "[22407 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_df = pd.read_csv(raw_bar_pass).set_index('ID')\n",
    "bar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2c5ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bar_df['age'] = bar_df['age'].abs()\n",
    "\n",
    "drop_cols_dup = ['DOB_yr','sex','bar2','race2','other','asian','black','hisp','bar','bar_passed','indxgrp','ugpa','indxgrp2','gender','race1'] #,'bar2_yr'\n",
    "drop_cols_na = ['decile1b','decile3','decile1','zgpa','zfygpa']\n",
    "one_hot_cols = ['grad','bar1','race','Dropout']\n",
    "bar_df = bar_df.drop(columns = drop_cols_dup + drop_cols_na)\n",
    "bar_df = bar_df.dropna()\n",
    "bar_df = pd.get_dummies(bar_df,columns = one_hot_cols)\n",
    "# sens_attri = ['other','asian','black','hisp', 'male','race1','race2', 'sex','race','DOB_yr','age','gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7057199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(bar_df, test_size=0.2, random_state=42)\n",
    "scaler = MinMaxScaler()#StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9380986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = pd.DataFrame(X_train_scaled,columns = X_train.columns,index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5ec7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17515, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865f79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(X_train_scaled.values,dtype=torch.float32)#.shape\n",
    "X_train_torch = torch.tensor(X_train_scaled,dtype=torch.float32)#.shape\n",
    "X_test_torch = torch.tensor(X_test_scaled,dtype=torch.float32)#.shape\n",
    "trainloader=DataLoader(dataset=X_train_torch,batch_size=1024)\n",
    "testloader=DataLoader(dataset=X_test_torch,batch_size=1024)\n",
    "\n",
    "# trainloader=DataLoader(dataset=X_train_torch,batch_size=12)\n",
    "# testloader=DataLoader(dataset=X_test_torch,batch_size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935d1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,D_in,H = 10, H2 = 12, latent_dim = 3):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        # Encoder\n",
    "        self.lin1 = nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.lin2 = nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features = H2)\n",
    "        self.lin3 = nn.Linear(H2,H2)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features = H2)\n",
    "        \n",
    "        # Latent\n",
    "        self.fc1 = nn.Linear(H2,latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features = latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim,latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim,latent_dim)\n",
    "        \n",
    "        #Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim,latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim,H2)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.lin4 = nn.Linear(H2,H2)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features = H2)\n",
    "        self.lin5 = nn.Linear(H2,H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features = H)\n",
    "        self.lin6 = nn.Linear(H,D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features = D_in)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        linear1 = self.relu(self.lin_bn1(self.lin1(x)))\n",
    "        linear2 = self.relu(self.lin_bn2(self.lin2(linear1)))\n",
    "        linear3 = self.relu(self.lin_bn2(self.lin2(linear2)))\n",
    "        \n",
    "        fc1 = F.relu(self.bn1(self.fc1(linear3)))\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "        \n",
    "        return r1,r2\n",
    "    \n",
    "    def reparameterize(self,mu,logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def decode(self,z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "        \n",
    "        linear4 = self.relu(self.lin_bn4(self.lin4(fc4)))\n",
    "        linear5 = self.relu(self.lin_bn5(self.lin5(linear4)))\n",
    "        return self.lin_bn6(self.lin6(linear5))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu,logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae600a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in = X_train_torch.shape[1]\n",
    "H = 50\n",
    "H2 = 12\n",
    "model = Autoencoder(D_in, H, H2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_mse = customLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d6f000d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_torch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65cb260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17515, 29])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a5da32a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Linear: 1-1, BatchNorm1d: 1-2, ReLU: 1-3, Linear: 1-4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchsummary/torchsummary.py:140\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 140\u001b[0m         _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 61\u001b[0m, in \u001b[0;36mAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 61\u001b[0m     mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu,logvar)\n",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m, in \u001b[0;36mAutoencoder.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m linear1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_bn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x)))\n\u001b[0;32m---> 35\u001b[0m linear2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_bn2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m linear3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_bn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(linear2)))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 50 elements not 12",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchsummary/torchsummary.py:143\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_data, batch_dim, branching, col_names, col_width, depth, device, dtypes, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    142\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchsummary. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(executed_layers)\n\u001b[1;32m    146\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchsummary. See above stack traces for more details. Executed layers up to: [Linear: 1-1, BatchNorm1d: 1-2, ReLU: 1-3, Linear: 1-4]"
     ]
    }
   ],
   "source": [
    "# summary(model, (50, 29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e92c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1500\n",
    "log_interval = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c620068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        print(data)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    if epoch % 200 == 0:        \n",
    "        print('====> Epoch: {} Average training loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(trainloader.dataset)))\n",
    "        train_losses.append(train_loss / len(trainloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1aa1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        for batch_idx, data in enumerate(testloader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            if epoch % 200 == 0:        \n",
    "                print('====> Epoch: {} Average test loss: {:.4f}'.format(\n",
    "                    epoch, test_loss / len(testloader.dataset)))\n",
    "            test_losses.append(test_loss / len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94d541d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4000, 0.7027, 0.1667,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.6081, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4000, 0.7297, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.4000, 0.8108, 0.1667,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.4000, 0.7297, 0.1667,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7568, 0.1667,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x12 and 50x12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     test(epoch)\n",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m recon_batch, mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_mse(recon_batch, data, mu, logvar)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 61\u001b[0m, in \u001b[0;36mAutoencoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 61\u001b[0m     mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu,logvar)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z), mu, logvar\n",
      "Cell \u001b[0;32mIn[11], line 36\u001b[0m, in \u001b[0;36mAutoencoder.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m linear1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_bn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(x)))\n\u001b[1;32m     35\u001b[0m linear2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_bn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(linear1)))\n\u001b[0;32m---> 36\u001b[0m linear3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_bn2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear2\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     38\u001b[0m fc1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(linear3)))\n\u001b[1;32m     39\u001b[0m r1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc21(fc1)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1024x12 and 50x12)"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130453e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f3852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fc608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bar_df.parttime.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb074b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df.Dropout.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df.dropna().pass_bar.value_counts(normalize=True)\n",
    "# bar_df.dropna().isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e96b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfa8ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48dae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df['bar'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3771564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_df = bar_df.fillna(0)\n",
    "bar_df.groupby(['bar','bar_passed']).size().unstack(fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c288d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df.groupby(['indxgrp','indxgrp2']).size().unstack(fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05558707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb83390",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df.groupby(['race','hisp','other','asian','black']).size().unstack(fill_value=0)#.reset_index()#.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df.groupby('race')['dnn_bar_pass_prediction'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df.groupby('gender')['dnn_bar_pass_prediction'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f94d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_by_age = bar_df.groupby(['age','bar_passed'],dropna = False).size().unstack(fill_value=0)\n",
    "pass_by_age['pass_rate'] = pass_by_age[True] / (pass_by_age[True]+pass_by_age[False])\n",
    "pass_by_age.sort_values('age',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30521b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_by_race = bar_df.groupby(['race1','bar_passed'],dropna = False).size().unstack(fill_value=0)\n",
    "pass_by_race['total'] = (pass_by_race[True]+pass_by_race[False])\n",
    "pass_by_race['pass_rate'] = pass_by_race[True] / pass_by_race['total']\n",
    "pass_by_race['proportion_total'] = pass_by_race['total']/pass_by_race['total'].sum()\n",
    "pass_by_race['proportion_failed'] = pass_by_race[False]/pass_by_race[False].sum()#*100\n",
    "pass_by_race['normalized_failure_likelihood'] = pass_by_race['proportion_failed']/pass_by_race['proportion_total']\n",
    "\n",
    "pass_by_race.sort_values('pass_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5baedd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_by_gender = bar_df.groupby(['gender','bar_passed'],dropna = False).size().unstack(fill_value=0)\n",
    "pass_by_gender['pass_rate'] = pass_by_gender[True] / (pass_by_gender[True]+pass_by_gender[False])\n",
    "pass_by_gender.sort_values('pass_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85a2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7854d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"/workspace/vae-fairness/data/raw/german.data-numeric\", delimiter=\",\")#.shape\n",
    "# pd.read_csv(german_all, delimiter=\"\\t\")\n",
    "# pd.read_csv(raw_bar_pass)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
